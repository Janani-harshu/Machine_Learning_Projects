{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab40d01",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-30T17:13:42.856720Z",
     "iopub.status.busy": "2022-03-30T17:13:42.856053Z",
     "iopub.status.idle": "2022-03-30T17:13:42.867413Z",
     "shell.execute_reply": "2022-03-30T17:13:42.868030Z"
    },
    "papermill": {
     "duration": 0.035227,
     "end_time": "2022-03-30T17:13:42.868395",
     "exception": false,
     "start_time": "2022-03-30T17:13:42.833168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\n",
      "/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5b6fa",
   "metadata": {
    "papermill": {
     "duration": 0.011288,
     "end_time": "2022-03-30T17:13:42.892805",
     "exception": false,
     "start_time": "2022-03-30T17:13:42.881517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Sarcasm has been part of our language for many years lol!\n",
    "It means being the opposite of what you mean, usually with a distinct tone of voice in a fun way. \n",
    "If you think that anyone can understand sarcasm, then you are wrong, because understanding sarcasm depends on your language skills and your knowledge of other people’s minds. \n",
    "\n",
    "But what about a computer? Is it possible to train a machine learning model that can detect whether a sentence is sarcastic or not? Yes, it is! \n",
    "\n",
    "In this notebook, I will walk you all through the task of Sarcasm Detection using the Bernoulli Naive Bayes algorithm!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325872c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:13:42.926470Z",
     "iopub.status.busy": "2022-03-30T17:13:42.922957Z",
     "iopub.status.idle": "2022-03-30T17:13:44.391966Z",
     "shell.execute_reply": "2022-03-30T17:13:44.392656Z",
     "shell.execute_reply.started": "2022-03-30T17:05:19.857872Z"
    },
    "papermill": {
     "duration": 1.488408,
     "end_time": "2022-03-30T17:13:44.392891",
     "exception": false,
     "start_time": "2022-03-30T17:13:42.904483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        article_link  \\\n",
      "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
      "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
      "2  https://local.theonion.com/mom-starting-to-fea...   \n",
      "3  https://politics.theonion.com/boehner-just-wan...   \n",
      "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
      "\n",
      "                                            headline  is_sarcastic  \n",
      "0  former versace store clerk sues over secret 'b...             0  \n",
      "1  the 'roseanne' revival catches up to our thorn...             0  \n",
      "2  mom starting to fear son's web series closest ...             1  \n",
      "3  boehner just wants wife to listen, not come up...             1  \n",
      "4  j.k. rowling wishes snape happy birthday in th...             0  \n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "data = pd.read_json(\"../input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15f524",
   "metadata": {
    "papermill": {
     "duration": 0.011268,
     "end_time": "2022-03-30T17:13:44.416511",
     "exception": false,
     "start_time": "2022-03-30T17:13:44.405243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The “is_sarcastic” column in this dataset contains the labels that we have to predict for the task of sarcasm detection. It contains binary values as 1 and 0, where 1 means sarcastic and 0 means not sarcastic. So for simplicity, I will transform the values of this column as “sarcastic” and “not sarcastic” instead of 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa7f828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:13:44.443674Z",
     "iopub.status.busy": "2022-03-30T17:13:44.442679Z",
     "iopub.status.idle": "2022-03-30T17:13:44.459721Z",
     "shell.execute_reply": "2022-03-30T17:13:44.459090Z",
     "shell.execute_reply.started": "2022-03-30T17:05:35.489934Z"
    },
    "papermill": {
     "duration": 0.031584,
     "end_time": "2022-03-30T17:13:44.459864",
     "exception": false,
     "start_time": "2022-03-30T17:13:44.428280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        article_link  \\\n",
      "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
      "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
      "2  https://local.theonion.com/mom-starting-to-fea...   \n",
      "3  https://politics.theonion.com/boehner-just-wan...   \n",
      "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
      "\n",
      "                                            headline is_sarcastic  \n",
      "0  former versace store clerk sues over secret 'b...  Not Sarcasm  \n",
      "1  the 'roseanne' revival catches up to our thorn...  Not Sarcasm  \n",
      "2  mom starting to fear son's web series closest ...      Sarcasm  \n",
      "3  boehner just wants wife to listen, not come up...      Sarcasm  \n",
      "4  j.k. rowling wishes snape happy birthday in th...  Not Sarcasm  \n"
     ]
    }
   ],
   "source": [
    "data[\"is_sarcastic\"] = data[\"is_sarcastic\"].map({0: \"Not Sarcasm\", 1: \"Sarcasm\"})\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3a0838",
   "metadata": {
    "papermill": {
     "duration": 0.012187,
     "end_time": "2022-03-30T17:13:44.484378",
     "exception": false,
     "start_time": "2022-03-30T17:13:44.472191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let’s prepare the data for training a machine learning model. This dataset has three columns, out of which we only need the “headline” column as a feature and the “is_sarcastic” column as a label. So let’s select these columns and split the data into 20% test set and 80% training set - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f304c7a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:13:44.517074Z",
     "iopub.status.busy": "2022-03-30T17:13:44.512048Z",
     "iopub.status.idle": "2022-03-30T17:13:45.013782Z",
     "shell.execute_reply": "2022-03-30T17:13:45.013185Z",
     "shell.execute_reply.started": "2022-03-30T17:05:55.537559Z"
    },
    "papermill": {
     "duration": 0.517201,
     "end_time": "2022-03-30T17:13:45.013940",
     "exception": false,
     "start_time": "2022-03-30T17:13:44.496739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[[\"headline\", \"is_sarcastic\"]]\n",
    "x = np.array(data[\"headline\"])\n",
    "y = np.array(data[\"is_sarcastic\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x) # Fit the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "546c8ed0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:13:45.045403Z",
     "iopub.status.busy": "2022-03-30T17:13:45.044231Z",
     "iopub.status.idle": "2022-03-30T17:13:45.172559Z",
     "shell.execute_reply": "2022-03-30T17:13:45.171936Z",
     "shell.execute_reply.started": "2022-03-30T17:06:13.199159Z"
    },
    "papermill": {
     "duration": 0.146503,
     "end_time": "2022-03-30T17:13:45.172714",
     "exception": false,
     "start_time": "2022-03-30T17:13:45.026211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8448146761512542\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb8c66",
   "metadata": {
    "papermill": {
     "duration": 0.012427,
     "end_time": "2022-03-30T17:13:45.197815",
     "exception": false,
     "start_time": "2022-03-30T17:13:45.185388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let’s use a sarcastic text as input to test whether our machine learning model detects sarcasm or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05023355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:13:45.226436Z",
     "iopub.status.busy": "2022-03-30T17:13:45.225800Z",
     "iopub.status.idle": "2022-03-30T17:13:45.332392Z",
     "shell.execute_reply": "2022-03-30T17:13:45.331721Z",
     "shell.execute_reply.started": "2022-03-30T17:06:35.254240Z"
    },
    "papermill": {
     "duration": 0.122197,
     "end_time": "2022-03-30T17:13:45.332682",
     "exception": true,
     "start_time": "2022-03-30T17:13:45.210485",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "StdinNotImplementedError",
     "evalue": "raw_input was called, but this frontend does not support input requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20/2434108460.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter a Text: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_stdin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             raise StdinNotImplementedError(\n\u001b[0;32m-> 1005\u001b[0;31m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m             )\n\u001b[1;32m   1007\u001b[0m         return self._input_request(\n",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m: raw_input was called, but this frontend does not support input requests."
     ]
    }
   ],
   "source": [
    "user = input(\"Enter a Text: \")\n",
    "data = cv.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37eac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:07:24.224930Z",
     "iopub.status.busy": "2022-03-30T17:07:24.224307Z",
     "iopub.status.idle": "2022-03-30T17:07:28.715705Z",
     "shell.execute_reply": "2022-03-30T17:07:28.715051Z",
     "shell.execute_reply.started": "2022-03-30T17:07:24.224899Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "user = input(\"Enter a Text: \")\n",
    "data = cv.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.193503,
   "end_time": "2022-03-30T17:13:46.055405",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-30T17:13:32.861902",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
